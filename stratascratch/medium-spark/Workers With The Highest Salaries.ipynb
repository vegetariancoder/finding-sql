{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+------+------------+----------+\n",
      "|worker_id|first_name|last_name|salary|joining_date|department|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "|        1|    Monika|    Arora|100000|  2014-02-20|        HR|\n",
      "|        2|  Niharika|    Verma| 80000|  2014-06-11|     Admin|\n",
      "|        3|    Vishal|  Singhal|300000|  2014-02-20|        HR|\n",
      "|        4|    Amitah|    Singh|500000|  2014-02-20|     Admin|\n",
      "|        5|     Vivek|    Bhati|500000|  2014-06-11|     Admin|\n",
      "|        6|     Vipul|    Diwan|200000|  2014-06-11|   Account|\n",
      "|        7|    Satish|    Kumar| 75000|  2014-01-20|   Account|\n",
      "|        8|   Geetika|  Chauhan| 90000|  2014-04-11|     Admin|\n",
      "|        9|     Agepi|    Argon| 90000|  2015-04-10|     Admin|\n",
      "|       10|       Moe|  Acharya| 65000|  2015-04-11|        HR|\n",
      "|       11|     Nayah|  Laghari| 75000|  2014-03-20|   Account|\n",
      "|       12|       Jai|    Patel| 85000|  2014-03-21|        HR|\n",
      "+---------+----------+---------+------+------------+----------+\n",
      "\n",
      "+-------------+-------------+-------------+\n",
      "|worker_ref_id| worker_title|affected_from|\n",
      "+-------------+-------------+-------------+\n",
      "|            1|      Manager|   2016-02-20|\n",
      "|            2|    Executive|   2016-06-11|\n",
      "|            8|    Executive|   2016-06-11|\n",
      "|            5|      Manager|   2016-06-11|\n",
      "|            4|Asst. Manager|   2016-06-11|\n",
      "|            7|    Executive|   2016-06-11|\n",
      "|            6|         Lead|   2016-06-11|\n",
      "|            3|         Lead|   2016-06-11|\n",
      "+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"strata\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "title = spark\\\n",
    "    .read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\",True)\\\n",
    "    .option(\"inferSchema\",True)\\\n",
    "    .option(\"delimiter\", \"\\t\")\\\n",
    "    .load(\"/Users/sahilnagpal/Desktop/finding-sql/stratascratch/data/title.csv\")\n",
    "\n",
    "title.show()\n",
    "\n",
    "worker = spark\\\n",
    "    .read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\",True)\\\n",
    "    .option(\"inferSchema\",True)\\\n",
    "    .option(\"delimiter\", \"\\t\")\\\n",
    "    .load(\"/Users/sahilnagpal/Desktop/finding-sql/stratascratch/data/worker.csv\")\n",
    "\n",
    "worker.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/27 14:20:21 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/07/27 14:20:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/07/27 14:20:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "| worker_title|\n",
      "+-------------+\n",
      "|Asst. Manager|\n",
      "|      Manager|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "title\\\n",
    "    .withColumn(\"drnk\",dense_rank().over(Window.orderBy(col(\"salary\").desc())))\\\n",
    "    .join(worker,title.worker_id == worker.worker_ref_id,\"inner\")\\\n",
    "    .filter(col(\"drnk\")==1)\\\n",
    "    .select(\"worker_title\")\\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}